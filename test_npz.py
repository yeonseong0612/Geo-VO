import os
import numpy as np
from tqdm import tqdm
from CFG.vo_cfg import vo_cfg as cfg

def check_data_sanity():
    base_dir = cfg.precomputed_dir
    seq_list = [s for s in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, s))]
    
    bad_files = []
    total_files = 0
    
    print(f"ğŸ•µï¸ ë°ì´í„° ë¬´ê²°ì„± ì¡°ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... (ëŒ€ìƒ: {len(seq_list)}ê°œ ì‹œí€€ìŠ¤)")

    for seq in seq_list:
        seq_path = os.path.join(base_dir, seq)
        files = [f for f in os.listdir(seq_path) if f.endswith('.npz')]
        
        for f in tqdm(files, desc=f"Checking {seq}", leave=False):
            total_files += 1
            file_path = os.path.join(seq_path, f)
            
            try:
                data = np.load(file_path)
                issues = []

                # 1. NaN ë˜ëŠ” Inf ì²´í¬ (ëª¨ë“  í‚¤ê°’ ëŒ€ìƒ)
                for key in data.files:
                    if np.isnan(data[key]).any():
                        issues.append(f"NaN in {key}")
                    if np.isinf(data[key]).any():
                        issues.append(f"Inf in {key}")

                # 2. 3D Points(pts_3d)ì˜ ìœ íš¨ì„± ì²´í¬
                pts_3d = data['pts_3d']
                # ê¹Šì´(Z)ê°€ 0ì´ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° (Bundle Adjustment í„°ì§€ëŠ” ì£¼ë²”)
                if (pts_3d[:, 2] <= 0).any():
                    zero_depth_count = np.sum(pts_3d[:, 2] <= 0)
                    issues.append(f"Zero/Neg Depth ({zero_depth_count} pts)")

                # 3. íŠ¹ì§•ì (kpts) ì¢Œí‘œ ë²”ìœ„ ì²´í¬ (ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€)
                # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • (cfg ì°¸ê³ : 1216, 352)
                kpts = data['kpts']
                if (kpts[:, 0] < 0).any() or (kpts[:, 0] > 1216).any() or \
                   (kpts[:, 1] < 0).any() or (kpts[:, 1] > 352).any():
                    issues.append("Kpts out of bounds")

                # 4. ì‚¼ê°í˜• ì¸ë±ìŠ¤(tri_indices) ë²”ìœ„ ì²´í¬
                if 'tri_indices' in data.files and data['tri_indices'].size > 0:
                    if data['tri_indices'].max() >= len(kpts):
                        issues.append("Invalid tri_indices (index error)")

                if issues:
                    bad_files.append(f"{seq}/{f} -> {' | '.join(issues)}")

            except Exception as e:
                bad_files.append(f"{seq}/{f} -> Error loading file: {str(e)}")

    # ê²°ê³¼ ë¦¬í¬íŠ¸
    print("\n" + "="*60)
    print(f"ğŸ“Š ë¬´ê²°ì„± ì¡°ì‚¬ ìš”ì•½")
    print(f" - ì „ì²´ ì¡°ì‚¬ íŒŒì¼: {total_files}ê°œ")
    print(f" - ê²°í•¨ ë°œê²¬ íŒŒì¼: {len(bad_files)}ê°œ")
    print("="*60)

    if bad_files:
        save_path = "data_integrity_report.txt"
        with open(save_path, "w") as out:
            for item in bad_files:
                out.write(item + "\n")
        print(f"ğŸš¨ ê²°í•¨ ë¦¬ìŠ¤íŠ¸ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”!")
    else:
        print("âœ… ëª¨ë“  ë°ì´í„°ê°€ ê¹¨ë—í•©ë‹ˆë‹¤! ëª¨ë¸ ë‚´ë¶€ ìˆ˜ì‹ì„ ì ê²€í•´ ë´…ì‹œë‹¤.")

if __name__ == "__main__":
    check_data_sanity()