import os
import torch
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import torchvision.transforms as T

from src.model import VO
from CFG.vo_cfg import vo_cfg  

class LastFrameDataset(Dataset):
    def __init__(self, cfg):
        self.cfg = cfg
        self.samples = []
        
        # KITTI í‘œì¤€ í•´ìƒë„ ê³ ì • (Dataloader stack ì—ëŸ¬ ë°©ì§€)
        self.target_h, self.target_w = 376, 1241 
        self.transform = T.Compose([
            T.Resize((self.target_h, self.target_w)), 
            T.ToTensor()
        ])
        
        # ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸ í• ë‹¹
        target_seqs = getattr(cfg, 'trainsequencelist', getattr(cfg, 'sequences', []))
        self.base_path = "/home/jnu-ie/Dataset/kitti_odometry/data_odometry_color/dataset/sequences/"

        print(f"ğŸ” íƒìƒ‰í•  ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸: {target_seqs}")

        for seq in target_seqs:
            img_dir = os.path.join(self.base_path, seq, "image_2")
            if not os.path.exists(img_dir):
                continue
            
            fnames = sorted([f for f in os.listdir(img_dir) if f.endswith('.png')])
            if fnames:
                last_f = fnames[-1]
                img_num = int(last_f.split('.')[0])
                self.samples.append((seq, img_num))
                print(f"âœ… ë°œê²¬: Sequence {seq}ì˜ ë§ˆì§€ë§‰ í”„ë ˆì„ì€ {img_num}ë²ˆ ì…ë‹ˆë‹¤.")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        seq, img_num = self.samples[idx]
        path_L = os.path.join(self.base_path, seq, "image_2", f"{str(img_num).zfill(6)}.png")
        path_R = os.path.join(self.base_path, seq, "image_3", f"{str(img_num).zfill(6)}.png")
        
        img_L = self.transform(Image.open(path_L).convert('RGB'))
        img_R = self.transform(Image.open(path_R).convert('RGB'))
        
        return {
            'images': torch.stack([img_L, img_R], dim=0), 
            'seq': seq, 
            'imgnum': img_num
        }

@torch.no_grad()
def export_last_only(model, dataloader, save_dir):
    model.eval()
    # 1. ì‚¬ìš©í•  ì¥ì¹˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê³ ì •
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    from scipy.spatial import Delaunay

    print(f"ğŸ¯ ëˆ„ë½ëœ ë§ˆì§€ë§‰ í”„ë ˆì„({len(dataloader.dataset)}ê°œ) ì „ì²˜ë¦¬ ì‹œì‘...")

    for batch in tqdm(dataloader):
        images = batch['images'].to(device)
        seqs = batch['seq']
        imgnums = batch['imgnum']
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¶”ì¶œ
        h, w = images.shape[-2:]
        # size_vecì„ ì—°ì‚° ì‹œì ì— deviceì— ë”± ë§ê²Œ ìƒì„±
        size_vec = torch.tensor([w, h], dtype=torch.float32, device=device).view(1, 2)

        for side_idx, side_name in zip([0, 1], ['image_2', 'image_3']):
            # extractor ê²°ê³¼ (list of tensors)
            kpts_list, desc_list = model.extractor(images[:, side_idx])
            
            for b in range(len(kpts_list)):
                # [ìˆ˜ì • í•µì‹¬] ê°œë³„ í…ì„œë¥¼ í•œ ë²ˆ ë” ëª…ì‹œì ìœ¼ë¡œ deviceë¡œ ì´ë™
                k = kpts_list[b].to(device)
                d = desc_list[b].to(device)
                
                # GPU ìƒì—ì„œ ì •ê·œí™” ì—°ì‚° ìˆ˜í–‰
                k_norm = k / size_vec 
                    
                if d.shape[0] == 256: 
                    d = d.transpose(0, 1)
                
                # CPU ê¸°ë°˜ í›„ì²˜ë¦¬(Delaunay, Save)ë¥¼ ìœ„í•´ ë„˜íŒŒì´ ë³€í™˜
                node_feat = torch.cat([d, k_norm], dim=-1).cpu().numpy()
                k_np = k.cpu().numpy()

                # Delaunay & Edges ìƒì„±
                if len(k_np) < 3:
                    edges_np = np.zeros((2, 0), dtype=np.int32)
                else:
                    tri = Delaunay(k_np)
                    edges = np.concatenate([
                        tri.simplices[:, [0, 1]], 
                        tri.simplices[:, [1, 2]], 
                        tri.simplices[:, [2, 0]]
                    ], axis=0)
                    edges_np = np.unique(np.sort(edges, axis=1), axis=0).T

                # Edge Attributes (Euclidean Distance)
                if edges_np.shape[1] > 0:
                    edge_attr = np.linalg.norm(k_np[edges_np[0]] - k_np[edges_np[1]], axis=1, keepdims=True)
                else:
                    edge_attr = np.zeros((0, 1), dtype=np.float32)

                # ì‹œí€€ìŠ¤ë³„ í´ë” êµ¬ì¡° ìƒì„± ë° ì €ì¥
                full_path = os.path.join(save_dir, seqs[b], side_name, f"{str(imgnums[b].item()).zfill(6)}.npz")
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                
                np.savez_compressed(
                    full_path, 
                    node_features=node_feat.astype(np.float16), 
                    edges=edges_np.astype(np.int32), 
                    edge_attr=edge_attr.astype(np.float16), 
                    kpts=k_np.astype(np.float32)
                )

if __name__ == "__main__":
    SAVE_PATH = "/home/jnu-ie/kys/Geo-VO/geovo_precomputed"
    
    # ëª¨ë¸ ë¡œë“œ
    model = VO(vo_cfg).cuda()
    print("âœ… ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ ì™„ë£Œ")

    dataset = LastFrameDataset(vo_cfg)
    # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ ë‹¬ë¼ stack ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ num_workers=0ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜
    # ì´ë¯¸ Dataset ë‹¨ê³„ì—ì„œ Resizeë¥¼ ë„£ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
    dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)
    
    if len(dataset) > 0:
        export_last_only(model, dataloader, SAVE_PATH)
        print("âœ¨ ëª¨ë“  ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ í”„ë ˆì„ ë³µêµ¬ ì™„ë£Œ!")
    else:
        print("ğŸ’¡ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")