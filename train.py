import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from tqdm import tqdm
from lietorch import SE3

# ì„¤ì • ë° ëª¨ë¸ ëª¨ë“ˆ ì„í¬íŠ¸
from CFG.vo_cfg import vo_cfg
from src.model import VO
from src.loader import DataFactory
from src.loss import total_loss

def setup():
    """DDP í™˜ê²½ ì´ˆê¸°í™”"""
    dist.init_process_group(backend="nccl")
    local_rank = int(os.environ["LOCAL_RANK"])
    torch.cuda.set_device(local_rank)
    return local_rank

def cleanup():
    """DDP ì¢…ë£Œ"""
    dist.destroy_process_group()

def train():
    # 1. DDP ì„¤ì •
    local_rank = setup()
    device = torch.device("cuda", local_rank)
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œëŠ” ë©”ì¸ í”„ë¡œì„¸ìŠ¤(0ë²ˆ)ì—ì„œë§Œ ìƒì„±
    if local_rank == 0:
        os.makedirs(vo_cfg.logdir, exist_ok=True)
        print(f"ğŸš€ GPU {dist.get_world_size()}ê°œì—ì„œ DDP ë³‘ë ¬ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {vo_cfg.logdir}")

    # 2. ëª¨ë¸ ì´ˆê¸°í™” ë° DDP ì ìš©
    model = VO(baseline=0.54).to(device)
    model = DDP(
        model, 
        device_ids=[local_rank], 
        output_device=local_rank,
        find_unused_parameters=True  
    )
    # 3. ë°ì´í„°ì…‹ ë° ë¡œë” ì„¤ì • (DistributedSampler í•„ìˆ˜)
    train_set = DataFactory(vo_cfg, mode='train')
    sampler = DistributedSampler(train_set, shuffle=True)
    
    train_loader = DataLoader(
        train_set, 
        batch_size=vo_cfg.batchsize,
        sampler=sampler,
        num_workers=vo_cfg.num_cpu,
        pin_memory=False, 
        drop_last=True,
        prefetch_factor=4    
    )

    # 4. ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = torch.optim.AdamW(model.parameters(), lr=vo_cfg.learning_rate)
    scheduler = optim.lr_scheduler.MultiStepLR(
        optimizer, 
        milestones=vo_cfg.MultiStepLR_milstone, 
        gamma=vo_cfg.MultiStepLR_gamma
    )

    # 5. ë©”ì¸ í•™ìŠµ ë£¨í”„
    for epoch in range(vo_cfg.maxepoch):
        model.train()
        sampler.set_epoch(epoch)  # ë§¤ ì—í­ë§ˆë‹¤ ë°ì´í„°ë¥¼ ë‹¤ë¥´ê²Œ ì…”í”Œë§
        epoch_loss = 0.0
        
        # tqdmì€ 0ë²ˆ GPUì—ì„œë§Œ ì¶œë ¥
        pbar = tqdm(train_loader, desc=f"Epoch [{epoch}/{vo_cfg.maxepoch}]") if local_rank == 0 else train_loader
        
        for i, batch in enumerate(pbar):
            optimizer.zero_grad()
            
            # ë°ì´í„° ë¡œë“œ ë° GPU ì „ì†¡
            images = batch['images'].to(device)
            intrinsics = batch['intrinsics'].to(device)
            gt_poses = SE3(batch['rel_pose'].to(device))

            # Forward Pass (ì´ì œ outputsëŠ” í•´ë‹¹ GPUì˜ ë…ë¦½ì ì¸ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤)
            outputs = model(images, intrinsics, iters=8)

            # [í•µì‹¬] ì´ì œ ë³µì¡í•œ gather_and_verify ì—†ì´ ëª¨ë¸ ì¶œë ¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            # DDPê°€ ë‚´ë¶€ì ìœ¼ë¡œ Gradientë¥¼ í•©ì³ì£¼ê¸° ë•Œë¬¸ì— ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            loss, l_pose, l_weight = total_loss(outputs, gt_poses, vo_cfg)            
            loss.backward()
            
            # Gradient Clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            epoch_loss += loss.item()
            
            # ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ ìƒíƒœ ì¶œë ¥
            if local_rank == 0 and i % 5 == 0:
                pbar.set_postfix({
                    "Loss": f"{loss.item():.6f}",
                    "LR": f"{optimizer.param_groups[0]['lr']:.6e}"
                })

        scheduler.step()
        
        # 6. ëª¨ë¸ ì €ì¥ (0ë²ˆ GPUì—ì„œë§Œ ìˆ˜í–‰)
        if local_rank == 0:
            avg_loss = epoch_loss / len(train_loader)
            checkpoint_path = os.path.join(vo_cfg.logdir, f"checkpoint_epoch_{epoch}.pth")
            
            # DDP ëª¨ë¸ì—ì„œ ì›ë˜ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ .module ì ‘ê·¼
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.module.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_loss,
            }, checkpoint_path)
            print(f"âœ… Epoch {epoch} ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.6f}")

    cleanup()
    if local_rank == 0:
        print("ğŸ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    train()