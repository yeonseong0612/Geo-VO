import os
import torch
import numpy as np
import cv2
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
import multiprocessing as mp
import torch.nn as nn

from src.model import VO
from CFG.vo_cfg import vo_cfg  

import os
import torch
import numpy as np
import cv2
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
import multiprocessing as mp

# --- [1] ì „ì²˜ë¦¬ ì „ìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (Crop ë¡œì§ ì ìš©) ---
class PreprocessDataset(Dataset):
    def __init__(self, data_root, sequences):
        self.data_root = data_root
        self.samples = []
        
        for seq in sequences:
            img_dir = os.path.join(data_root, seq, 'image_2')
            if not os.path.exists(img_dir): continue
            
            img_names = sorted([f for f in os.listdir(img_dir) if f.endswith('.png')])
            
            for name in img_names:
                img_num = int(name.split('.')[0])
                self.samples.append({
                    'seq': seq,
                    'imgnum': img_num,
                    'img_path_2': os.path.join(data_root, seq, 'image_2', name),
                    'img_path_3': os.path.join(data_root, seq, 'image_3', name)
                })

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        s = self.samples[idx]
        img2_raw = cv2.imread(s['img_path_2'])
        img3_raw = cv2.imread(s['img_path_3'])
        
        imgs_processed = []
        for raw_img in [img2_raw, img3_raw]:
            # 1. BGR -> RGB ë³€í™˜
            img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
            H, W, _ = img.shape
            
            # 2. ì›ë˜ ëª¨ë¸ í¬ë¡­ ë¡œì§: 32 ë°°ìˆ˜ ë§ì¶”ê¸° ë° ê°€ë¡œ 1216 ì œí•œ
            # H % 32ë¥¼ í†µí•´ ìƒë‹¨ì„ ì³ëƒ„
            img = img[H % 32:, :1216]
            
            # 3. [ì¤‘ìš”] ì‹œí€€ìŠ¤ ê°„ ë¯¸ì„¸í•œ ì„¸ë¡œ í¬ê¸° ì°¨ì´ ë°©ì§€
            # KITTI sequences 00-08ì€ ë³´í†µ í¬ë¡­ í›„ 352 í˜¹ì€ 384ê°€ ë˜ëŠ”ë°, 
            # ë°°ì¹˜ë¥¼ ë¬¶ê¸° ìœ„í•´ ê°•ì œë¡œ 352ë¡œ ë§ì¶¥ë‹ˆë‹¤. (ëŒ€ë¶€ë¶„ 352ì„)
            if img.shape[0] != 352 or img.shape[1] != 1216:
                img = cv2.resize(img, (1216, 352), interpolation=cv2.INTER_LINEAR)
            
            # 4. Tensorí™” [H, W, C] -> [C, H, W]
            imgs_processed.append(torch.from_numpy(img).permute(2, 0, 1).float() / 255.0)
        
        # ì´ì œ ëª¨ë“  ì´ë¯¸ì§€ê°€ (3, 352, 1216)ì´ë¯€ë¡œ stack ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ
        return {
            'images': torch.stack(imgs_processed), # [2, 3, 352, 1216]
            'seq': s['seq'],
            'imgnum': s['imgnum']
        }

# --- [1] save_worker ìˆ˜ì •: 800ê°œë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥ (DT ì—°ì‚° ì œê±°) ---
def save_worker(task_data):
    try:
        # ì´ì œ ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ DT(Delaunay)ë¥¼ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
        # Selectorê°€ ì ì„ ê³ ë¥¸ ë’¤ì— í•™ìŠµ ì‹œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
        kpts_np = task_data['kpts']
        node_features = task_data['node_features']
        rel_path = task_data['rel_path'] 
        save_dir = task_data['save_dir']
        
        full_save_path = os.path.join(save_dir, rel_path + ".npz")
        os.makedirs(os.path.dirname(full_save_path), exist_ok=True)

        # 800ê°œì˜ ì¢Œí‘œì™€ 256ì°¨ì› ë””ìŠ¤í¬ë¦½í„°ë§Œ ì••ì¶• ì €ì¥
        np.savez_compressed(
            full_save_path,
            node_features=node_features.astype(np.float16), # ìš©ëŸ‰ ì ˆì•½ì„ ìœ„í•œ fp16
            kpts=kpts_np.astype(np.float32)
        )
    except Exception as e:
        print(f"Error saving {rel_path}: {e}")

@torch.no_grad()
def export_parallel(model, dataloader, save_dir, num_cpu):
    model.eval()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device) 

    pool = mp.Pool(processes=num_cpu)
    async_results = []

    for batch in tqdm(dataloader, desc="SuperPoint Raw Extraction"):
        images = batch['images'].to(device) # [B, 2, 3, 352, 1216]
        B = images.shape[0]
        seqs = batch['seq']
        imgnums = batch['imgnum'] 

        for side_idx, side_name in zip([0, 1], ['image_2', 'image_3']):
            # [ìˆ˜ì •] 800ê°œ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ë½‘ìŠµë‹ˆë‹¤. (Selectorë¥¼ ê±°ì¹˜ì§€ ì•ŠìŒ!)
            kpts_raw, desc_raw = model.extractor(images[:, side_idx])
            
            tasks = []
            for b in range(B):
                # ì›ë³¸ 800ê°œì™€ 256ì°¨ì› ìœ ì§€
                k = kpts_raw[b]     
                d = desc_raw[b]   
                
                file_name = f"{int(imgnums[b]):06d}" 
                rel_path = os.path.join(seqs[b], side_name, file_name)

                tasks.append({
                    'kpts': k.cpu().numpy(),
                    'node_features': d.cpu().numpy(),
                    'rel_path': rel_path,
                    'save_dir': save_dir
                })
            
            res = pool.map_async(save_worker, tasks)
            async_results.append(res)

        # ì„¸ì…˜ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
        if len(async_results) > 20:
            for r in async_results[:10]: r.wait()
            async_results = async_results[10:]

    pool.close()
    pool.join()

if __name__ == "__main__":
    RAW_DATA_PATH = "/home/jnu-ie/Dataset/kitti_odometry/data_odometry_color/dataset/sequences" 
    SAVE_PATH = "/home/jnu-ie/kys/Geo-VO/gendata/precomputed"
    SEQUENCES = [f"{i:02d}" for i in range(9)] # 00~08
    
    vo_cfg.use_precomputed = False
    model = VO(vo_cfg).cuda()
    
    dataset = PreprocessDataset(RAW_DATA_PATH, SEQUENCES)
    print(f"ğŸ” ì°¾ì€ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(dataset)}") # 0ì´ ë‚˜ì˜¤ë©´ ê²½ë¡œ ë¬¸ì œì…ë‹ˆë‹¤.
    
    if len(dataset) > 0:
        dataloader = DataLoader(dataset, batch_size=vo_cfg.batchsize, num_workers=4, shuffle=False)
        export_parallel(model, dataloader, SAVE_PATH, num_cpu=vo_cfg.num_cpu)
        print(f"âœ¨ ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {SAVE_PATH}")
    else:
        print("âŒ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. RAW_DATA_PATHë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")