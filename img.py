import torch
import numpy as np
from src.model import VO
from CFG.vo_cfg import vo_cfg as cfg

def test_vo_dimensions(model, cfg):
    print("ğŸš€ VO Model Dimension & Selection Test Start...")
    
    # 1. ê°€ìƒ ë°ì´í„° ìƒì„± (Batch=2, Images=4, H=352, W=1216)
    B = 2
    dummy_imgs = torch.randn(B, 4, 3, 352, 1216).cuda()
    dummy_calib = torch.tensor([[700, 700, 600, 180]] * B).float().cuda()
    
    batch = {
        'imgs': dummy_imgs,
        'calib': dummy_calib
    }

    model.cuda()
    model.eval()

    with torch.no_grad():
        print("\n--- [Step 1: Extraction & Selection] ---")
        # forward ë¡œì§ì˜ ì‹œì‘ ë¶€ë¶„ ì‹œë®¬ë ˆì´ì…˜
        V = 4
        imgs_stacked = dummy_imgs.view(B * V, 3, 352, 1216)
        k_all_raw, f_all_raw = model.extractor(imgs_stacked)
        print(f"Raw Extraction: Keypoints {k_all_raw.shape}, Descriptors {f_all_raw.shape}")
        
        # Selector í†µê³¼
        top_k = 128
        f_all, k_all, indices = model.selector(k_all_raw, f_all_raw, (352, 1216), top_k=top_k)
        print(f"After Selection: Keypoints {k_all.shape}, Descriptors {f_all.shape}")
        
        # âš ï¸ ì§ˆë¬¸ 1 í…ŒìŠ¤íŠ¸: 800ê°œê°€ ì•„ë‹Œ 128ê°œê°€ ë“¤ì–´ê°€ëŠ”ê°€?
        actual_n = k_all.shape[1]
        if actual_n == top_k:
            print(f"âœ… Success: Model is using {actual_n} selected points.")
        else:
            print(f"âŒ Error: Model is still carrying {actual_n} points (Expected {top_k}).")

        # âš ï¸ ì§ˆë¬¸ 2 í…ŒìŠ¤íŠ¸: ë””ìŠ¤í¬ë¦½í„°ê°€ 128ì¸ê°€ 256ì¸ê°€?
        actual_desc_dim = f_all.shape[-1]
        print(f"âœ… Descriptor Dimension: {actual_desc_dim}")
        
        print("\n--- [Step 2: Splitting & Flow] ---")
        # í˜„ì¬ ì½”ë“œì˜ view(B, V, 800, ...) ë¶€ë¶„ì„ ì²´í¬
        try:
            k_split = k_all.view(B, V, actual_n, 2)
            f_split = f_all.view(B, V, actual_n, actual_desc_dim)
            print(f"Splitting OK: k_split {k_split.shape}, f_split {f_split.shape}")
        except RuntimeError as e:
            print(f"âŒ View Error: {e}")

        # 3. ì „ì²´ forward ì‹¤í–‰ ì‹œ ê° ëª¨ë“ˆì˜ ì…ë ¥ ì°¨ì› í™•ì¸ì„ ìœ„í•´ 
        # ëª¨ë¸ ë‚´ë¶€ ê³³ê³³ì— print(f_Lt.shape) ë“±ì„ ì„ì‹œë¡œ ë„£ê³  ì‹¤í–‰í•´ë´…ë‹ˆë‹¤.
        output = model(batch, iters=1, mode='test')
        
        print("\n--- [Step 3: Final Output Check] ---")
        print(f"Number of iterative poses: {len(output['poses'])}")
        print(f"Final Pose Shape: {output['poses'][-1].data.shape}")

if __name__ == "__main__":
    # 1. ì‹¤ì œ ëª¨ë¸ ê°ì²´ ìƒì„±
    # cfg ê°ì²´ê°€ í•„ìš”í•˜ë¯€ë¡œ ì´ì „ì— ì •ì˜í•œ cfgë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.
    my_vo_model = VO(cfg) 
    
    # 2. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ
    test_vo_dimensions(my_vo_model, cfg)